{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd96e777",
   "metadata": {},
   "source": [
    "# RAG 검토 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b187acc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='정확히 그 제목의 논문이 제 지식 범위(2024-10)에는 확실히 등록되어 있지 않습니다. 다만 2023–2024년에 RAG를 종합적으로 다룬 설문(survey) 논문들이 다수 있었고, 제목이 유사한 최신 설문이 2025년에 나왔을 가능성은 있습니다. 혹시 저자명, 연도, arXiv ID나 링크를 알려주실 수 있을까요? 주시면 핵심 기여와 구조를 빠르게 요약해 드리겠습니다. 원하시면 그 논문을 기준으로 RAG 파이프라인(인덱싱/청크/질의확장·재랭킹·생성·평가), 고급 주제(멀티홉/하이브리드 검색/그래프·에이전트·툴 사용/메모리), 평가(정확성·근거성·환각 억제)까지 정리해 드릴 수도 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1510, 'prompt_tokens': 46, 'total_tokens': 1556, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1280, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CRH9J2YIzx2bDB8HXM4fk8mxIcp3l', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3254ce90-63a5-486a-9220-70ab27dfdada-0', usage_metadata={'input_tokens': 46, 'output_tokens': 1510, 'total_tokens': 1556, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1280}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-5\")\n",
    "model.invoke(\"Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely 라는 제목의 논문을 알고있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e37e8b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='정확히 그 제목의 논문은 제 지식 범위(2024-10)에는 확실히 기억나지 않습니다. 아마 최근 프리프린트일 수 있어요. 링크나 저자/연도 정보를 주시면 확인해서 요약과 핵심 기여, 한계까지 정리해 드릴게요.\\n\\n참고로 유사 주제로는 다음이 자주 언급됩니다:\\n- Self-RAG (Asai et al., 2023): 검색-생성-자기평가로 신뢰성 향상\\n- RAGAS 등 RAG 평가 메트릭: groundedness/attribution 기반의 사실성 평가\\n- 거부 학습 관련: Constitutional AI, Llama Guard/거부 정책 미세조정\\n\\n원하시면 “근거 귀속 측정 + 약한 근거 시 거부 학습”을 RAG 파이프라인에 적용하는 설계/평가 방법도 제안해 드릴 수 있어요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1244, 'prompt_tokens': 41, 'total_tokens': 1285, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CRHACZHzq8C2naM0GCcR6Cp7MKRbl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--46db9068-e282-421d-93e9-f9488508deb7-0', usage_metadata={'input_tokens': 41, 'output_tokens': 1244, 'total_tokens': 1285, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse 라는 제목의 논문을 알고있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0a4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='정확히 그 제목의 논문이 제 지식 범위(2024-10까지)에는 확실히 잡히지 않습니다. 아주 최근의 프리프린트이거나, 제목이 약간 변형되어 알려졌을 가능성이 있어요. 링크(arXiv/DOI)나 저자·연도 정보를 알려 주시면 확인해서 요약해 드릴 수 있습니다.\\n\\n참고로, 질문하신 주제와 가까운 공개 연구로는:\\n- Morris II: Self-Replicating Prompt-Injection Worm (2024) — 프롬프트 인젝션 “웜”이 이메일·웹 등을 통해 전파되고 데이터 유출을 유도하는 개념과 실증을 다룹니다.\\n- RAG 보안 관련 연구들(예: 데이터베이스/인덱스 오염, 프롬프트 인젝션을 통한 데이터 유출, RAG 체인의 신뢰 경계 약화 등)을 다룬 여러 논문과 서베이들이 2023–2024년에 다수 있습니다.\\n\\n찾는 방법 제안:\\n- Google Scholar나 arXiv에서 “RAG jailbreaking worm data exfiltration” 조합으로 검색\\n- 제목을 큰따옴표로 묶어 그대로 검색\\n- 저자명 단서가 있으면 “author:name RAG jailbreak worm” 식으로 보조 검색\\n\\n링크나 PDF를 주시면 빠르게 핵심 기여, 위협 모델, 공격 기법, 평가 및 방어 시사점을 정리해 드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1363, 'prompt_tokens': 47, 'total_tokens': 1410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CRHCjiiMfFfzRIB4WgtyPw6aEerU5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cc3190c-92ee-4326-bcef-17a3aa1f686a-0', usage_metadata={'input_tokens': 47, 'output_tokens': 1363, 'total_tokens': 1410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2024 년 9월 8일 (모름 위로 갈수록 최신)\n",
    "model.invoke(\"Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking 라는 제목의 논문을 알고 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35e50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네, 알고 있습니다. 긴 컨텍스트 LLM 시대에도 RAG가 여전히 중요하다는 점을 실험적으로 옹호하는 연구(주로 arXiv에 공개)입니다. 요지는 다음과 같습니다.\\n\\n- 긴 컨텍스트에 자료를 “그냥 다 넣기”는 주의 분산과 비용 문제로 성능이 꾸준히 오르지 않으며, 종종 RAG가 더 정확하고 효율적이다.\\n- 적절한 검색과 재순위(reranking)를 통해 관련 증거를 압축해 넣는 것이 정답률, 지연시간, 비용에서 유리하다.\\n- 컨텍스트 길이를 크게 늘려도 증거가 문서 곳곳에 희석되면 모델이 정확히 참조하지 못하는 경우가 많다.\\n- 하이브리드 전략(필요 증거는 RAG로 뽑고, 장문 맥락이나 글로벌 정보는 제한적으로 추가)이 가장 안정적이다.\\n\\n원하시면 더 자세한 요약, 핵심 실험 결과, 실무 적용 체크리스트, 또는 인용 정보(제목/연도/링크)도 정리해 드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1224, 'prompt_tokens': 31, 'total_tokens': 1255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CRHB0LtbMwR2DiDqLpUbhjvhGRy48', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--75e772eb-8655-4b9a-b705-20d821d8215e-0', usage_metadata={'input_tokens': 31, 'output_tokens': 1224, 'total_tokens': 1255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 960}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2024 년 9월 3일(알고 있음)\n",
    "model.invoke(\"In Defense of RAG in the Era of Long-Context Language Models 라는 제목의 논문을 알고있어?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481fca9",
   "metadata": {},
   "source": [
    "# Agent 검토 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1155432d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='제 지식 기준(2024-10)으로는 “Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents”라는 정확한 제목의 논문은 확인되지 않습니다. 아마 새로 나온 작업이거나, 프리프린트/블로그 포스트/프로젝트 이름일 수 있어요.\\n\\n가능하면 아래 정보를 알려주시면 찾아드리거나 요약해 드릴게요.\\n- 저자명\\n- 발표 연도/학회(또는 arXiv ID, 링크)\\n- 관련 키워드나 문맥\\n\\n참고로 비슷한 주제의 대표적 작업으로는 ReAct, Reflexion, Voyager(오픈엔드 RL/에이전트 학습), AutoGPT/AutoGen(도구 활용 에이전트) 등이 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 881, 'prompt_tokens': 30, 'total_tokens': 911, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CRHcj73PYXZwRH6Z4B9wt7ue1m0Zs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--76d3413d-57b6-4525-90cb-e69cca08d462-0', usage_metadata={'input_tokens': 30, 'output_tokens': 881, 'total_tokens': 911, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모른다. \n",
    "model.invoke(\"Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents 라는 제목의 ai 논문을 알고있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98798fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AxDeepScholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
