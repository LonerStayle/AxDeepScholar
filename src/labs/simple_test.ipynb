{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3327b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "current_dir = Path.cwd()\n",
    "root_dir = current_dir\n",
    "for parent in current_dir.parents:\n",
    "    if (parent / \"src\" / \"data\").exists():\n",
    "        root_dir = parent\n",
    "        break\n",
    "    \n",
    "pdf_folder = root_dir / \"src\" / \"data\"\n",
    "pdf_paths = sorted(pdf_folder.rglob(\"*.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labs.document_parser import parse_with_docling\n",
    "\n",
    "pdf_path = pdf_paths[0]\n",
    "docs = parse_with_docling(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103934a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[11]['page_content'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a727f73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4536df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Published': '2025-09-03', 'Title': 'VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results', 'Authors': 'Dasong Li, Sizhuo Ma, Hang Hua, Wenjie Li, Jian Wang, Chris Wei Zhou, Fengbin Guan, Xin Li, Zihao Yu, Yiting Lu, Ru-Ling Liao, Yan Ye, Zhibo Chen, Wei Sun, Linhan Cao, Yuqin Cao, Weixia Zhang, Wen Wen, Kaiwei Zhang, Zijian Chen, Fangfang Lu, Xiongkuo Min, Guangtao Zhai, Erjia Xiao, Lingfeng Zhang, Zhenjie Su, Hao Cheng, Yu Liu, Renjing Xu, Long Chen, Xiaoshuai Hao, Zhenpeng Zeng, Jianqin Wu, Xuxu Wang, Qian Yu, Bo Hu, Weiwei Wang, Pinxin Liu, Yunlong Tang, Luchuan Song, Jinxi He, Jiaru Wu, Hanjia Lyu', 'Summary': 'This paper presents an overview of the VQualA 2025 Challenge on Engagement Prediction for Short Videos, held in conjunction with ICCV 2025. The challenge focuses on understanding and modeling the popularity of user-generated content (UGC) short videos on social media platforms. To support this goal, the challenge uses a new short-form UGC dataset featuring engagement metrics derived from real-world user interactions. This objective of the Challenge is to promote robust modeling strategies that capture the complex factors influencing user engagement. Participants explored a variety of multi-modal features, including visual content, audio, and metadata provided by creators. The challenge attracted 97 participants and received 15 valid test submissions, contributing significantly to progress in short-form UGC video engagement prediction.'}, page_content='VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods\\nand Results\\nDasong Li∗\\nSizhuo Ma∗\\nHang Hua∗\\nWenjie Li∗\\nJian Wang∗\\nChris Wei Zhou∗\\nFengbin Guan\\nXin Li\\nZihao Yu\\nYiting Lu\\nRu-Ling Liao\\nYan Ye\\nZhibo Chen\\nWei Sun\\nLinhan Cao\\nYuqin Cao\\nWeixia Zhang\\nWen Wen\\nKaiwei Zhang\\nZijian Chen\\nFangfang Lu\\nXiongkuo Min\\nGuangtao Zhai\\nErjia Xiao\\nLingfeng Zhang\\nZhenjie Su\\nHao Cheng\\nYu Liu\\nRenjing Xu\\nLong Chen\\nXiaoshuai Hao\\nZhenpeng Zeng\\nJianqin Wu\\nXuxu Wang\\nQian Yu\\nBo Hu\\nWeiwei Wang\\nPinxin Liu\\nYunlong Tang\\nLuchuan Song\\nJinxi He\\nJiaru Wu\\nHanjia Lyu\\nAbstract\\nThis paper presents an overview of the VQualA 2025 Chal-\\nlenge on Engagement Prediction for Short Videos, held in\\nconjunction with ICCV 2025. The challenge focuses on un-\\nderstanding and modeling the popularity of user-generated\\ncontent (UGC) short videos on social media platforms. To\\nsupport this goal, the challenge uses a new short-form UGC\\ndataset featuring engagement metrics derived from real-\\nworld user interactions. This objective of the Challenge is\\nto promote robust modeling strategies that capture the com-\\nplex factors influencing user engagement. Participants ex-\\nplored a variety of multi-modal features, including visual\\ncontent, audio, and metadata provided by creators. The\\nchallenge attracted 97 participants and received 15 valid\\ntest submissions, contributing significantly to progress in\\nshort-form UGC video engagement prediction.\\n1. Introduction\\nWith the rapid rise of social media, a growing number\\nof content creators are sharing short videos that capture\\ntheir daily lives on platforms like TikTok, Instagram Reels,\\nYouTube Shorts, and Snapchat Spotlight. At the same time,\\na large share of users are spending significant amounts of\\ntime watching this type of content across these platforms.\\nSocial media platforms receive a constant stream of\\n∗Dasong Li (dasongli@link.cuhk.edu.hk), Sizhuo Ma (sma@snap.com),\\nHang Hua (hhua2@cs.rochester.edu), Wenjie Li (wenjie.li@snap.com),\\nJian\\nWang\\n(jwang4@snap.com),\\nand\\nChris\\nWei\\nZhou\\n(zhouw26@cardiff.ac.uk) are the challenge organizers of this chal-\\nlange.\\nThe other authors are participants of the VQualA 2025 EVQA-SnapUGC:\\nEngagement prediction for short videos Challenge.\\nThe\\nproject\\npage\\nis\\nhttps : / / github . com / dasongli1 /\\nSnapUGC_Engagement/tree/main/ECR_inference\\nnewly published short videos. The effective dissemination\\nof newly published videos remains a core objective for so-\\ncial media platforms.\\nRecommending high-quality User\\nGenerated Content (UGC) videos enhances viewer engage-\\nment and consequently encourages content creators, espe-\\ncially novice creators. The effective dissemination of newly\\npublished videos remains a core goal of social media plat-\\nforms. However, owing to their limited user reactions, ac-\\ncurate recommendation of such cold-start items is usually\\na challenge. Typically, platforms would present each new\\nvideo to a restricted number of users, such as one hundred.\\nThe latent popularity of each video is estimated based on the\\nengagement metrics such as watch times from these initial\\nusers, serving as a basis for further recommendations. The\\ncold start problem [23, 34, 44, 59] arises from the sampling\\nbias in such limited initial interactions, resulting in noisy\\nand inaccurate predictions of recommendation extents. Ad-\\nditionally, this conventional approach can result in time-\\nsensitive short videos not being broadcast promptly, caus-\\ning them to miss critical attention. Furthermore, emerging\\ncreators may struggle to gain sufficient visibility and rec-\\nommendations, limiting their potential impact. Content cre-\\nators may also face delays in gauging their videos’ popular-\\nity, slowing their adjustments based on viewer feedback and\\nthus discouraging them from posting more quality content.\\nConsequently, an ineffective cold-start process may creates\\na negative feedback loop within the ecosystem, hindering\\nthe recommendation of high-quality videos to users, espe-\\ncially for some small-size or mid-size s')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "arxiv = ArxivAPIWrapper(top_k_results=1)   # ← 여기를 늘리면 됨)\n",
    "arxiv_result = arxiv.load(f\"\"\"2025\"\"\")\n",
    "print(arxiv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1735b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(\n",
    "    model = \"gpt-4.1-mini\"\n",
    ")\n",
    "\n",
    "result = model.invoke(f\"아래내용 번역좀 해줘\\n{arxiv_result[0].page_content}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae4ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 요청하신 내용의 한국어 번역입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## GenIR(생성 정보 검색)의 기초  \n",
      "Qingyao Ai¹†, Jingtao Zhan¹†, Yiqun Liu¹  \n",
      "¹청화대학교 컴퓨터과학기술학과,  \n",
      "중국 베이징  \n",
      "기여 저자: aiqy@tsinghua.edu.cn;  \n",
      "zhanjt20@mails.tsinghua.edu.cn; yiqunliu@tsinghua.edu.cn;  \n",
      "†본 연구에 동등하게 기여한 저자들입니다.\n",
      "\n",
      "### 초록  \n",
      "이 장에서는 현대 생성 AI 모델이 정보 접근(IA; Information Access) 시스템에 미치는 기초적인 영향을 논의한다. 전통적인 AI와 달리, 대규모 학습 및 우수한 데이터 모델링을 갖춘 생성 AI 모델은 고품질의 사람과 유사한 응답을 생성할 수 있어, 정보 접근 패러다임 발전에 새로운 기회를 제공한다. 본 장에서는 그 중 두 가지를 구체적으로 소개하는데, 바로 정보 생성과 정보 종합이다.\n",
      "\n",
      "정보 생성은 AI가 사용자 필요에 맞춤화된 콘텐츠를 직접 만들어 즉각적이고 관련성 높은 결과를 제공함으로써 사용자 경험을 향상시키는 것을 의미한다. 정보 종합은 생성 AI가 기존 정보를 통합·재구성하는 능력을 활용하여 근거가 있는 답변을 제공하고 모델 착각(허위 정보 생성) 문제를 완화하며, 특히 정밀성과 외부 지식이 요구되는 상황에서 가치가 크다.  \n",
      "\n",
      "본 장은 생성 모델의 기초적인 측면인 아키텍처, 확장, 학습 방식을 다루며, 멀티모달 시나리오에서의 응용을 논의한다. 또한, 검색 보강 생성(retrieval-augmented generation) 패러다임과 코퍼스 모델링 및 이해를 위한 기타 방법들을 살펴봄으로써 생성 AI가 정보 접근 시스템을 어떻게 향상시킬 수 있는지 보여준다. 마지막으로 잠재적 도전 과제와 미래 연구의 유망한 방향을 정리한다.\n",
      "\n",
      "현대 생성 모델과 전통 AI 기법의 주된 차이는 인간의 지시에 따라 복잡하고 고품질의 출력을 생성할 수 있다는 점이다. 여러 연구 [1–3]에서 보여주듯, 현대 생성 AI 모델은 인간과의 상호작용을 매우 유사하게 모방하는 뛰어난 응답 생성 능력을 보유하고 있다. 일반적으로 이러한 놀라운 성능은 대규모 학습 데이터 세트와 첨단 데이터 모델링 알고리즘에서 비롯된다.  \n",
      "\n",
      "이들의 탁월한 데이터 이해 능력은 문서 인코딩, 인덱스 구축, 질의 처리, 관련성 분석 등 기존 정보 접근 시스템의 거의 모든 구성 요소에 이득이 될 수 있다. 그러나 생성 AI가 정보 접근에 독특하게 가져다주는 새로운 기회나 패러다임에 대해 말할 때, 이를 크게 두 가지 방향으로 분류할 수 있다.  \n",
      "\n",
      "첫 번째는 사용자의 정보 요구를 직접 해결하는 콘텐츠 생성이다. 사용자 질의를 입력 지시사항으로 이해하고 받아들이면서 생성 AI 모델은 개인의 요청에 맞춘 구체적인 답변이나 산출물을 생성할 수 있다. 이러한 정보 생성에 대한 직접적인 접근은 즉각적이고 관련성 높은 응답을 제공하여 사용자 경험을 크게 향상시킨다.\n",
      "\n",
      "두 번째 방향은 생성 AI 모델의 진보된 지시 이행 능력을 활용해 기존 정보를 새롭고 창의적인 방식으로 종합·재조합하는 것이다. 대형 언어 모델(LLM)과 같은 생성 AI는 기존 데이터를 받아서 이전에 명확히 드러나지 않았던 새로운 일관성 있는 정보로 변환할 수 있다. 정보를 재해석하고 재구성하는 이 능력은 검색 시스템 설계와 응용 분야에 새로운 가능성을 열어준다.\n",
      "\n",
      "따라서 본 장에서는 정보 생성과 정보 종합, 두 가지 관점에서 생성 AI 모델이 정보 접근을 어떻게 도울 수 있는지 논의한다.\n",
      "\n",
      "---\n",
      "\n",
      "1. 정보 생성  \n",
      "정보 요구는 다양하며 보통 롱테일(드물고 특수한 요구)이다. 검색 엔진이나 추천 플랫폼 같은 전통적 정보 검색 시스템은 이미 존재하는 정보를 제공하도록 설계되었다. 그러나 이러한 시스템들은 덜 일반적인 정보 요구를 충족시키는 데 한계가 있는 경우가 많다. (이하 내용 생략)\n",
      "\n",
      "---\n",
      "\n",
      "필요하시면 나머지 내용도 이어서 번역해 드리겠습니다!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be63001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'The method is not allowed for the requested URL.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "\n",
    "payload = {\n",
    "    \"query\": \"LLM RAG embedding\",\n",
    "    \"fields\": \"title,abstract,embedding\",\n",
    "    \"limit\": 3\n",
    "}\n",
    "\n",
    "res = requests.post(url, json=payload)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db6e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AxDeepScholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
