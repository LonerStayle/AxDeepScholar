<page><text>Published as a conference paper at ICLR 2025
6
RESULTS AND ANALYSIS
Table 2: LLaMA family evaluated on the ASQA, QAMPARI, and ELI5 datasets. Best values within
each family are highlighted ). AR% := Answered Ratio in %; F1AC := Answer Correctness F1;
F1GR := Grounded Refusals F1; F1GC := Grounded Citations F1; TRUST := TRUST-SCORE; Resp.
:= Responsiveness; Att-Grd. := Attribution Groundedness.
Model
Type
ASQA (610 answerable, 338 unanswerable)
QAMPARI (295 answerable, 705 unanswerable)
ELI5 (207 answerable, 793 unanswerable)
Resp.
Trustworthiness
Resp.
Trustworthiness
Resp.
Trustworthiness
AR (%)
Truthfullness
Att-Grd.
TRUST
AR (%)
Truthfullness
Att-Grd.
TRUST
AR (%)
Truthfullness
Att-Grd.
TRUST
F1AC
F1GR
F1GC
F1AC
F1GR
F1GC
F1AC
F1GR
F1GC
LLaMA-2
-7b
ICL
0.00
0.00
26.28
0.00
8.76
0.00
0.00
41.35
0.00
13.78
0.50
0.00
46.71
0.00
15.57
PostCite
10.44
0.07
35.23
0.00
11.77
34.40
0.00
57.34
9.50
22.28
0.90
1.86
44.98
5.04
17.29
PostAttr
10.44
0.07
35.23
0.00
11.77
34.40
0.00
57.34
3.78
20.37
0.90
1.86
44.98
0.00
15.61
Self-RAG
100.00
45.19
39.15
63.49
49.28
96.00
6.81
28.23
19.95
18.33
73.50
14.94
40.20
13.80
22.98
FRONT
100.00
60.47
39.15
68.86
56.16
100.00
17.27
22.78
24.26
21.44
100.00
21.66
17.15
52.72
30.51
TRUST-ALIGN (DPO)
65.30
52.48
66.12
83.94
67.51
32.30
32.03
71.67
49.42
51.04
21.60
22.54
63.27
47.35
44.39
LLaMA-2
-13b
ICL
17.41
21.52
41.40
13.83
25.58
26.50
0.44
59.57
0.00
20.00
46.40
19.97
54.81
4.73
26.50
PostCite
90.51
2.21
49.91
1.53
17.88
100.00
0.00
22.78
8.05
10.28
76.60
2.27
38.05
0.72
13.68
PostAttr
90.51
2.21
49.91
0.17
17.43
100.00
0.00
22.78
2.95
8.58
76.60
2.27
38.05
0.09
13.47
Self-RAG
100.00
48.52
39.15
69.79
52.49
72.70
2.71
48.58
26.91
26.07
22.10
12.77
58.68
24.54
32.00
LLaMA-3.2
-1b
ICL
60.23
35.95
50.94
9.96
32.28
19.20
6.32
52.64
0.38
19.78
88.40
12.87
27.10
5.23
15.07
PostCite
43.57
0.59
50.22
0.24
17.02
41.20
0.32
49.79
1.61
17.24
18.40
2.04
50.88
1.02
17.98
PostAttr
45.78
0.48
48.42
0.00
16.30
34.00
0.63
48.43
0.21
16.42
18.40
2.04
50.88
0.07
17.66
FRONT
79.11
48.22
54.48
48.29
50.33
98.60
7.57
24.54
15.32
15.81
97.20
16.11
20.76
30.19
22.35
TRUST-ALIGN (DPO)
41.67
38.64
58.61
79.35
58.87
20.00
27.22
67.92
49.42
48.19
9.60
13.20
59.35
48.21
40.25
LLaMA-3.2
-3b
ICL
1.27
2.04
27.98
53.95
27.99
34.10
16.06
59.65
12.87
29.53
21.90
18.55
55.56
30.70
34.94
PostCite
47.26
31.03
56.59
22.99
36.87
39.60
6.34
55.22
6.83
22.80
92.80
18.12
25.14
4.44
15.90
PostAttr
47.15
29.76
56.71
4.69
30.39
42.00
5.10
53.74
0.27
19.70
92.80
18.48
25.14
0.53
14.72
FRONT
95.25
63.19
49.45
57.46
56.70
92.70
12.99
32.89
19.19
21.69
86.90
19.95
32.21
41.97
31.38
TRUST-ALIGN (DPO)
77.85
59.82
66.38
84.21
70.14
48.20
29.13
70.85
45.65
48.54
17.50
18.33
62.79
55.87
45.66
LLaMA-3
-8b
ICL
1.48
3.01
28.58
86.50
39.36
3.90
5.92
48.60
20.24
24.92
0.00
0.00
44.23
0.00
14.74
PostCite
77.53
32.98
53.31
28.01
38.10
87.00
6.10
34.52
8.42
16.35
62.00
20.80
45.88
8.06
24.91
PostAttr
77.53
32.98
53.31
5.95
30.75
87.00
6.10
34.52
1.64
14.09
62.00
20.80
45.88
1.25
22.64
FRONT
99.05
62.25
41.62
66.14
56.67
100.00
13.53
22.78
20.42
18.91
99.50
18.99
17.85
44.69
27.18
TRUST-ALIGN (DPO)
56.43
53.94
65.49
88.26
69.23
22.40
35.35
70.73
58.77
54.95
15.50
20.81
63.57
50.24
44.87
TRUST-ALIGN boosts trustworthiness over baseline methods.
As shown in Table 2 and Ta-
ble 3, TRUST-ALIGNed models demonstrate substantial improvements on TRUST-SCORE over the
baselines in 26 out of 27 model family and dataset configurations. Specifically, with LLaMA-3-8b,
TRUST-ALIGN outperforms FRONT by 12.56% (ASQA), 36.04% (QAMPARI), and 17.69% (ELI5)
on TRUST-SCORE. This suggests that TRUST-ALIGNed models are more capable of generating re-
sponses grounded in the documents.
TRUST-ALIGN improves models’ refusal capability.
Across all 27 configurations, TRUST-
ALIGN yields substantial improvements in F1GR. In LLaMA-3-8b, TRUST-ALIGN outperforms
FRONT by 23.87% (ASQA), 47.95% (QAMPARI), and 45.72% (ELI5). This indicates that TRUST-
ALIGN substantially enhances models’ ability to correctly refuse or provide answers.
TRUST-ALIGN enhances models’ citation quality.
F1GC is substantially improved over base-
lines in 24 out of 27 model family and dataset configurations after the application of TRUST-ALIGN.
Specifically, with LLaMA-3-8b, TRUST-ALIGN outperforms FRONT on F1GC by 22.12% (ASQA),
38.35% (QAMPARI), and 5.55% (ELI5). This demonstrates that aligning with TRUST-ALIGN im-
proves the model’s ability to provide citations that sufficiently and precisely support claims.
TRUST-ALIGN has mixed effects on F1AC.
We observe that applying TRUST-ALIGN yields a
notable increase in F1AC for QAMPARI (9/9) but mixed performance on ELI5 (5/9) and ASQA
(2/9). The mixed performance in ASQA and ELI5 can be explained by the composition of F1AC,
which is derived from PAC and RAC (Eq. (9)).
Taking LLaMA-3.2-3b on ASQA as an example (Appendix I), TRUST-ALIGN models generally
achieve higher PAC compared to baselines (54.63% for TRUST-ALIGN vs. 52.94% for FRONT)
despite having a lower AR% (77.85% for TRUST-ALIGN vs. 95.25% for FRONT). This suggests
that our models have a higher expected value for ACq (per-sample AC recall), as the denominator
depends on the number of answered questions. This trend is observed across models and datasets.
7</text></page>