<page><text>Published as a conference paper at ICLR 2025
However, in ASQA and ELI5, our models underperform in F1AC due to the overwhelmingly ad-
verse impact of RAC. The recall of answerable questions (Rans) is lower for our model compared to
baselines (89.02% for TRUST-ALIGN vs. 98.69% for FRONT), which rarely refuse questions. As
a result, fewer terms are summed in the numerator of RAC, while the denominator remains constant
(the number of answerable questions). This leads to a lower overall F1AC score. To further analyze
the baseline models’ performance, we investigated how much of their answering ability relies on
parametric knowledge versus document-based information (Section 6.1 and Appendix F.3).
Table 3: Qwen2.5 and Phi3.5 families evaluated on the three datasets.
Model
Type
ASQA (610 answerable, 338 unanswerable)
QAMPARI (295 answerable, 705 unanswerable)
ELI5 (207 answerable, 793 unanswerable)
Resp.
Trustworthiness
Resp.
Trustworthiness
Resp.
Trustworthiness
AR (%)
Truthfullness
Att-Grd.
TRUST
AR (%)
Truthfullness
Att-Grd.
TRUST
AR (%)
Truthfullness
Att-Grd.
TRUST
F1AC
F1GR
F1GC
F1AC
F1GR
F1GC
F1AC
F1GR
F1GC
Qwen-2.5
-0.5b
ICL
29.85
20.96
47.19
0.35
22.83
11.40
2.45
50.67
0.00
17.71
82.30
13.73
33.14
0.37
15.75
PostCite
46.10
8.55
50.84
8.23
22.54
17.00
0.67
52.51
5.72
19.63
89.80
9.87
27.10
4.10
13.69
PostAttr
46.10
8.55
50.84
2.23
20.54
17.00
0.67
52.51
0.90
18.03
89.80
9.87
27.10
0.68
12.55
FRONT
100.00
42.83
39.15
45.87
42.62
99.30
11.52
23.23
15.90
16.88
99.90
13.74
17.29
27.95
19.66
TRUST-ALIGN (DPO)
71.84
50.59
61.28
52.40
54.76
17.90
15.76
61.84
29.73
35.78
21.70
13.68
60.79
22.72
32.40
Qwen-2.5
-1.5b
ICL
98.52
50.55
41.74
6.69
32.99
85.00
15.60
41.27
8.61
21.83
99.40
20.56
17.78
4.99
14.44
PostCite
71.73
16.36
52.46
15.40
28.07
11.20
3.44
51.11
13.95
22.83
91.50
15.63
26.71
5.17
15.84
PostAttr
71.73
16.36
52.46
4.45
24.42
11.20
3.44
51.11
1.07
18.54
91.50
15.63
26.71
0.62
14.32
FRONT
99.26
57.74
41.36
55.70
51.60
98.80
16.05
24.45
11.60
17.37
99.90
19.57
17.29
37.70
24.85
TRUST-ALIGN (DPO)
72.57
52.68
62.38
66.81
60.62
20.00
23.80
68.46
50.98
47.75
33.60
19.03
57.91
31.63
36.19
Qwen-2.5
-3b
ICL
27.43
37.72
51.36
51.72
46.93
22.30
23.17
63.27
41.20
42.55
68.80
29.12
46.31
34.34
36.59
PostCite
8.76
9.58
35.30
10.94
18.61
0.10
0.00
41.31
0.00
13.77
49.70
21.73
48.49
7.56
25.93
PostAttr
8.76
9.58
35.30
36.29
27.06
0.10
0.00
41.31
25.00
22.10
49.70
21.73
48.49
1.31
23.84
FRONT
97.47
55.15
44.01
62.72
53.96
79.10
20.69
48.62
25.67
31.66
93.60
18.69
25.37
37.40
27.15
TRUST-ALIGN (DPO)
49.47
55.19
63.76
78.64
65.86
48.10
35.69
70.31
45.64
50.55
13.50
22.52
64.38
42.01
42.97
Qwen-2.5
-7b
ICL
92.09
58.94
54.34
75.46
62.91
56.30
28.92
63.67
39.28
43.96
82.70
28.27
37.13
44.13
36.51
PostCite
91.46
27.52
45.93
4.19
25.88
26.70
8.59
60.16
1.05
23.27
95.60
21.82
22.23
7.03
17.03
PostAttr
91.46
27.52
45.93
17.92
30.46
26.70
8.59
60.16
13.55
27.43
95.60
21.82
22.23
0.96
15.00
FRONT
86.39
64.58
60.08
58.27
60.98
84.70
17.02
42.85
24.48
28.12
57.60
28.27
54.14
56.61
46.34
TRUST-ALIGN (DPO)
59.49
55.04
66.22
83.57
68.28
32.10
30.11
70.68
53.48
51.42
21.00
24.30
63.79
47.02
45.04
Phi3.5
-mini
ICL
63.19
50.24
51.95
42.64
48.28
70.20
11.91
43.90
12.26
22.69
81.50
27.59
37.17
30.14
31.63
PostCite
23.10
14.98
41.38
9.40
21.92
76.90
3.57
42.36
4.49
16.81
84.50
20.50
30.81
4.67
18.66
PostAttr
23.10
14.98
41.38
1.24
19.20
76.90
3.57
42.36
0.46
15.46
84.50
21.26
30.81
0.68
17.58
FRONT
99.79
63.30
39.79
71.63
58.24
100.00
11.97
22.78
21.50
18.75
96.60
21.46
21.35
61.41
34.74
TRUST-ALIGN (DPO)
66.56
52.23
64.20
85.36
67.26
30.10
36.42
73.95
53.40
54.59
24.90
23.39
67.62
47.42
46.14
TRUST-ALIGN generalizes across model families and sizes.
Table 3 demonstrates that TRUST-
ALIGN improves the models’ TRUST-SCORE across various sizes and architectures. In small mod-
els like Qwen-2.5-0.5b, TRUST-ALIGN significantly outperforms ICL baselines, achieving notable
gains in ASQA (22.83% →54.76%). Similarly, for larger models such as Qwen-2.5-7b, TRUST-
ALIGN delivers substantial improvements, as seen in ASQA (62.91% →68.28%), highlighting its
scalability. The largest gains are observed in smaller models; for example, Phi3.5-mini shows re-
markable improvements over ICL: 18.98% (ASQA), 31.90% (QAMPARI), and 14.51% (ELI5).
Models aligned with DPO generally outperform those trained with SFT.
Table 4 shows that
DPO models outperform SFT models on TRUST-SCORE in 26 out of 27 model family and dataset
configurations. In LLaMA-3.2-3b, DPO yields substantial improvements on ASQA (6.70%), QAM-
PARI (3.09%), and ELI5 (1.71%). Additionally, DPO models also attain substantially better F1GC
compared to SFT on 25 out of 27 configurations, with substantial improvements on ASQA (8.58%),
QAMPARI (7.62%), and ELI5 (2.54%) for LLaMA-3.2-3b. This highlights DPO’s effectiveness in
enhancing citation quality. While results on F1AC and F1GR are mixed, DPO yields better overall
TRUST-SCORE scores.
6.1
ANALYSIS
Data ablation.
Table 5 shows that adding samples targeting each of the five hallucination types
improves TRUST-SCORE by 1.50% (ASQA), 1.78% (QAMPARI), and 2.23% (ELI5). We observe
that removing data corresponding to each hallucination type causes a notable decrease in TRUST-
SCORE, suggesting the importance of each subtype. In particular, removing refusal-related hallu-
cinations adversely affects F1GR: ↓2.79% (ASQA), ↓0.48% (QAMPARI), underscoring the impor-
tance of incorporating refusal-related data to improve a model’s ability to discern when to provide
an answer.
8</text></page>