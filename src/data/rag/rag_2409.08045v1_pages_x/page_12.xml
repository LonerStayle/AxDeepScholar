<page><text>Figure 7: The influence of the number of hops of the propaga-
tion (top) and the GenAI engine employed (bottom).
3.5 Sonnet. This time we fixed the context size k = 10.
Results. As can be seen from the results presented in Fig. 7,
the GenAI engine highly affects the replication &amp; payload
success rate of the worm. When the worm was applied against
Claude 3.5 Sonnet, the replication &amp; payload success rates
maintained around 100% but when the worm was applied
against Gemini 1.5 Pro, the replication &amp; payload success
rates decreased to 64% in the 20th hop of propagation.
In Appendix C, we evaluate the precision, recall/coverage,
and error rate of the GenAI engines in extracting confidential
user information. We note that this evaluation essentially tests
the performance of the GenAI engine in the task of NER
(name entity recognition).
5
Guardrails for RAG-based Inference
In this section, we review and analyze possible guardrails
for RAG-based GenAI-powered applications, comparing their
effectiveness against five families of RAG-based attacks: (1)
the worm (presented in Section 4), (2) RAG documents ex-
traction (presented in Section 3), (3) membership inference
attacks [2,3], (4) RAG entity extraction attacks [4], and (5)
RAG poisoning attacks [5–9]. The guardrails are analyzed
according to their effectiveness: the guardrail used to elimi-
nate (prevent) the attack (denoted as  ), the guardrail used to
mitigate the attack but does not prevent it (denoted as G#), and
the guardrail is ineffective against the attack (denoted as #).
A summary of the analysis is presented in Table 1.
5.1
Analysis
(1) Database Access Control - This guardrail restricts the
insertion of new documents to documents created by trusted
parties and authorized entities. Access control can be used for
securing the integrity of the data stored in database against
poisoning (insertion of new compromised documents) by pro-
hibiting the insertion of the content generated by untrusted
users into the database of the RAG:  - against RAG poison-
ing attacks and the worm, #- against membership inference
attacks, RAG entity extraction attacks and RAG documents
extraction attack.
(2) API Throttling - This guardrail intends to restrict a
user’s number of probes to the system by limiting the number
of queries a user can perform to a GenAI-powered application
(and to the database used by the RAG). This method prevents
an attacker from repeatedly probing the GenAI-powered ap-
plication to extract information from it. However, attackers
can bypass this method and apply the attack in a distributed
manner using multiple sessions opened via different users:
G#- against RAG documents extraction, RAG entity extraction
attacks, and membership inference attacks, #- against RAG
poisoning attacks and the worm.
(3) Thresholding - This guardrail intends to restrict the
data extracted in the retrieval by setting a minimum thresh-
old to the similarity score, limiting the retrieval to relevant
documents that crossed a threshold. This method prevents
an attacker from extracting documents that are irrelevant to
the query due to a threshold retrieval policy of retrieving up
to k documents that received the highest similarity score by
setting a minimum similarity threshold. However, attackers
can bypass this method by creating inputs whose similarity
score is high using adaptive probing techniques: G#- against
RAG document extraction, RAG entity extraction, worm, and
membership inference attacks, #- RAG poisoning attacks.
(4) Human in the Loop - This guardrail intends to vali-
date input to GenAI-powered applications (i.e., input to the
RAG) and responses (i.e., outputs from GenAI engines) using
humans. Humans can detect risky inputs (e.g., jailbreaking
attempts) and risky outputs (e.g., exfiltrated data or generated
toxic content) as long as the data is visible. However, human
feedback is ineffective against obfuscated inputs/outputs and
prone to mistakes due to decreased attention stemming from
over-reliance on computers, tiredness, and unknowing the
risks: G#- against RAG documents extraction and member-
ship inference attacks, RAG entity extraction, RAG poisoning
attacks and worm.
(5) Content Size Limit - This guardrail intends to restrict
the length of user inputs. This guardrail can prevent attackers
from providing inputs consisting of long jailbreaking com-
mands. However, attackers can use adaptive techniques to jail-
break a GenAI engine using shorter text: G#- against RAG doc-
uments extraction and membership inference attacks, RAG
entity extraction, RAG poisoning attacks and worm.
12</text></page>